机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。其所研究的主要内

容，是关于在计算机上从数据中产生“模型”(model)的算法，即“学习算法”(learning 

algorithm)。
本书中，“模型”泛指从数据中学得的结果，有的文献中用“模型”指全局性结果

，而用“模式”指局部性结果。

归纳与演绎是科学推理的两大基本手段， 前者是从特殊到一般的“泛化”过程，即从具体的事实

归结出一般性规律；后者则是从一般到特殊的“特化”，即从基础原理推导出具体状况。
学习过

程可以看作是一个在所有假设组成的空间中进行搜索的过程，目的是找到与训练集匹配的假设。

而现实中，可能会有多个假设与训练集一致，即存在一个与训练集一致的“假设集合”，称之为

“版本空间”。

需要注意，任何一个机器学习算法都必有其归纳偏好，否则将无法产生确定的学习结果。
一个神

奇的结论：对于算法A来说，若其在某些方面比算法B好，那么必然存在一些方面B比A好。这个结

论对任何算法均成立，无一例外！

“没有免费的午餐”定理(No Free Lunch Theorem, NFL)：无

论学习算法A多么聪明，学习算法B多么笨拙，它们的期望性能完全一样（总误差与学习算法无关

）。
但是需要注意，NFL定理的前提是所有问题出现的机会相同或者所有问题同等重要，但是实际

情形并不是这样。
那么NFL定理有什么用呢？
NFL定理是让我们意识到：脱离具体问题而空泛的谈

论哪一个算法更好毫无意义！

需要认识到，欠拟合通常是因为学习能力低下而导致的，这一点可以较容易克服，然而过拟合是

无法彻底避免的，所能做的只有运用各种方法来缓解，常见的缓解过拟合的方法有正则化与

dropout等。

有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较了:先使用某种实验评估

方法测得学习器的某个性能度量结果，然后对这些结果进行比较.但怎么来做这个"比较"呢?是直

接取得性能度量的值然后"比大小"吗?实际上，机器学习中性能比较这件事要比大家想象的复杂得

多.这里面涉及几个重要因素:首先，我们希望比较的是泛化性能，然而通过实验评估方法我们获

得的是测试集上的性能，两者的对比结果可能未必相同;第二，测试集上的性能与测试集本身的选

择有很大关系，且不论使用不同大小的测试集会得到不同的结果，即使用相同大小的测试集?若包

含的测试样例不同，测试结果也会有不同;第二，很多机器学习算法本身有一定的随机性，即便用

相同的参数设置在同一个测试集上多次运行，其结果也会有不同.
